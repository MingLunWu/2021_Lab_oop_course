from transformers import AutoTokenizer
from transformers import BertTokenizer

model_name = 'bert-base-uncased'
# åˆæ¬¡åŸ·è¡Œæœƒè‡ªå‹•ä¸‹è¼‰ç›¸é—œæª”æ¡ˆ
# tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer = BertTokenizer.from_pretrained(model_name)

# åŸºæœ¬ç”¨æ³•
encoded_text = tokenizer.encode("We are very happy to show you the ğŸ¤— Transformers library.")
reverse_text = tokenizer.decode(encoded_text)

# é€²éšç”¨æ³• (æ ¹æ“šéœ€è¦åŠ å…¥åƒæ•¸)
pt_batch = tokenizer(
    ["We are very happy to show you the ğŸ¤— Transformers library.", "We hope you don't hate it."],
    padding=True,
    truncation=True,
    max_length=100
)

print("Stop Here!")